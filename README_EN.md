<h1 align="center">ğŸ¨ Pixelle MCP</h1>

<p align="center">âœ¨ An AIGC solution based on MCP protocol that seamlessly converts ComfyUI workflows into Agent tools with zero code, combining the power of LLM and ComfyUI.</p>

<p align="center"><a href="README.md">ä¸­æ–‡</a> | <b>English</b></p>

https://github.com/user-attachments/assets/281812a8-f630-40ef-8eea-95efee05a985

## ğŸ“ Project Structure

- **mcp-client**: ğŸŒ MCP client with Web interface built on Chainlit
- **mcp-server**: ğŸ—„ï¸ MCP server providing various AIGC tools and services

## ğŸš€ Features

- [x] ğŸ”„ Support full-modal TISV (Text, Image, Sound/Speech, Video) conversion and generation
- [x] ğŸ§© Built on [ComfyUI](https://github.com/comfyanonymous/ComfyUI), inheriting all capabilities from ComfyUI's open ecosystem
- [x] ğŸ”§ Implemented Workflow-as-MCP-Tool solution with zero-code development for dynamic MCP Tool addition
- [x] ğŸ”Œ Server based on [MCP](https://modelcontextprotocol.io/introduction) protocol, supporting integration with any MCP client (including but not limited to Cursor, Claude Desktop, etc.)
- [x] ğŸ’» Client developed with [Chainlit](https://github.com/Chainlit/chainlit) framework, inheriting Chainlit's UI interaction components and supporting integration with more MCP Servers

## ğŸƒâ€â™‚ï¸ Quick Start

### ğŸ“¥ 1. Clone Repository & Configure Settings

#### ğŸ“¦ 1.1 Clone Repository

```shell
git clone https://github.com/AIDC-AI/Pixelle-MCP.git
cd Pixelle-MCP
```

#### ğŸ—„ï¸ 1.2 Configure Server

```shell
cd mcp-server
cp .env.example .env
# Modify .env configuration as needed
```

#### ğŸŒ 1.3 Configure Client

```shell
cd mcp-client
cp .env.example .env
# Modify .env configuration as needed
```

### ğŸ”§ 2. Add MCP Tools (Optional)

This step is optional and only determines your Agent's capabilities without affecting normal conversation. You can skip this if not needed immediately.

The `mcp-server/workflows` directory contains a default set of popular workflows. Run the following command to copy them to your mcp-server, and they will be automatically converted to MCP Tools when the service starts, available for LLM calls.

**Note: We strongly recommend testing workflows in your ComfyUI canvas before copying to ensure smooth execution during subsequent calls.**

```shell
cp -r mcp-server/workflows mcp-server/data/custom_workflows
```

### ğŸš€ 3. Start Services

#### ğŸ³ 3.1 Docker Launch (Recommended)

```shell
docker compose --profile all up -d
```

After completion, the following services will be available:

- **Client**: ğŸŒ http://localhost:9003 (Chainlit Web UI)
- **Server**: ğŸ—„ï¸ http://localhost:9002/sse (MCP Server)
- **MinIO**: ğŸ“¦ http://localhost:9001 (Object Storage Management Interface)

#### ğŸ› ï¸ 3.2 Source Code Launch

a. ğŸ“¦ Run [minio](https://github.com/minio/minio) service yourself and update the corresponding Minio configuration in `mcp-client/.env` and `mcp-server/.env`

b. ğŸ Install [uv](https://github.com/astral-sh/uv) environment

c. ğŸ—„ï¸ Start Server

```shell
# Enter directory
cd mcp-server
# Install dependencies (only needed for first time or updates)
uv sync
# Start service
uv run main.py
```

d. ğŸŒ Start Client

```shell
# Enter directory
cd mcp-client
# Install dependencies (only needed for first time or updates)
uv sync
# Start service
uv run main.py
```

## ğŸ› ï¸ Add Your Own MCP Tools

âš¡ One workflow equals one MCP Tool

### ğŸ¯ 1. Add the Simplest MCP Tool

* ğŸ“ Build a workflow in ComfyUI that implements image Gaussian blur ([Download workflow](docs/i_blur_ui.json)), then change the title of the `LoadImage` node to `$image.image!`, as shown below
![](docs/easy-workflow.png)

* ğŸ“¤ Export it as an API format file and rename to `i_blur.json`. You can export it yourself or use our pre-exported version ([Download here](docs/i_blur.json))

* ğŸ“‹ Copy the exported API format workflow file (Note: must be API format), input it in the web page, and let LLM add this Tool

  ![](docs/ready_to_send.png)

* âœ¨ After sending the message, LLM will automatically convert this workflow into an MCP Tool

  ![](docs/added_mcp.png)

* ğŸ¨ Now refresh the page and send any image to perform Gaussian blur processing through LLM

  ![](docs/use_mcp_tool.png)

### ğŸ”Œ 2. Add Complex MCP Tools

ğŸ“Š The process for adding MCP Tools is the same as before, the only difference is the workflow part (Download workflows: [UI format](docs/t2i_by_flux_turbo_ui.json) and [API format](docs/t2i_by_flux_turbo.json))

![](docs/t2i_by_flux_turbo.png)

## ğŸ”§ ComfyUI Workflow Custom Specifications

### ğŸ¨ Workflow Format
The system supports ComfyUI workflows. Simply design your workflow in the canvas and export it as API format. Define parameters and outputs using special syntax in node titles.

### ğŸ“ Parameter Definition Specifications

In ComfyUI canvas, double-click node titles to edit using the following DSL syntax:

```
$<parameter_name>.<field_name>[!][:<description>]
```

#### ğŸ” Syntax Explanation:
- `parameter_name`: Parameter name for the generated MCP tool function
- `field_name`: Corresponding input field name in the node
- `!`: Indicates this parameter is required
- `description`: Parameter description

#### ğŸ’¡ Operation Examples:

**Required Parameter Example:**

- Set LoadImage node title to: `$image.image!:Input image URL`
- Meaning: Creates a required parameter named `image` corresponding to the node's `image` field

**Optional Parameter Example:**

- Set `EmptyLatentImage` node title to: `$width.width:Image width, default 512`
- Meaning: Creates an optional parameter named `width` corresponding to the node's `width` field, with default value of 512 set in the node

### ğŸ¯ Type Inference Rules

The system automatically infers parameter types based on current node field values:
- ğŸ”¢ `int` type: Integer values (e.g., 512, 1024)
- ğŸ“Š `float` type: Float values (e.g., 1.5, 3.14)
- âœ… `bool` type: Boolean values (e.g., true, false)
- ğŸ“ `str` type: String values (default type)

### ğŸ“¤ Output Definition Specifications

#### ğŸ¤– Method 1: Automatic Output Node Recognition
The system automatically recognizes the following common output nodes:
- ğŸ–¼ï¸ `SaveImage` - Image save node
- ğŸ¬ `SaveVideo` - Video save node
- ğŸ”Š `SaveAudio` - Audio save node
- ğŸ“¹ `VHS_SaveVideo` - VHS video save node
- ğŸµ `VHS_SaveAudio` - VHS audio save node

#### ğŸ¯ Method 2: Manual Output Marking
> Generally used in scenarios with multiple outputs
Use `$output.variable_name` in any node's title to mark output:
- Set node title to: `$output.result`
- The system will use this node's output as the tool's return value

### ğŸ“„ Tool Description Configuration (Optional)

You can add a node titled `MCP` in your workflow to provide tool description:

1. Add a `String (Multiline)` or similar text node (must comply with: single string attribute, and node field must be one of the following: value, text, string)
2. Set node title to: `MCP`
3. Enter detailed tool description in the node's value field

### ğŸ¨ Complete Operation Example

Using image blur processing tool as example:

1. **ğŸ“¥ Add LoadImage Node**
   - Set default image
   - Change title to: `$image.image!:Image URL to be processed`

2. **ğŸŒ€ Add ImageBlur Node**
   - Connect to LoadImage output
   - Set blur radius to 15
   - Change title to: `$blur_radius.blur_radius:Blur radius, higher values mean more blur`

3. **ğŸ’¾ Add SaveImage Node**
   - Connect to ImageBlur output
   - Keep title as `Save Image` (automatically recognized by system)

4. **ğŸ“ Add Description Node (Optional)**
   - Add `String (Multiline)` node
   - Set title to: `MCP`
   - Set value to: `Image blur processing tool that applies Gaussian blur to input images`

### âš ï¸ Important Notes

1. **ğŸ”’ Parameter Validation**: Parameters marked as optional (without ! symbol) must have default values set in the node
2. **ğŸ”— Node Connections**: Fields already connected to other nodes will not be parsed as parameters
3. **ğŸ·ï¸ Tool Naming**: The exported filename will be used as the tool name; meaningful English names are recommended
4. **ğŸ“‹ Detailed Descriptions**: Provide detailed explanations in parameter descriptions to improve user experience
5. **ğŸ¯ Export Format**: Must export as API format, not UI format

## ğŸ¤ How to Contribute

We welcome all forms of contributions! Whether you're a developer, designer, or user, you can participate in building the project through the following ways:

### ğŸ› Report Issues
* ğŸ“‹ Submit bug reports on the [Issues](https://github.com/AIDC-AI/Pixelle-MCP/issues) page
* ğŸ” Please search for similar issues before submitting
* ğŸ“ Please describe the reproduction steps and environment information in detail

### ğŸ’¡ Feature Suggestions
* ğŸš€ Submit feature requests in [Issues](https://github.com/AIDC-AI/Pixelle-MCP/issues)
* ğŸ’­ Describe the features you'd like to add and their use cases
* ğŸ¯ Explain how the feature would improve user experience

### ğŸ”§ Code Contributions

#### ğŸ“‹ Contribution Process
1. ğŸ´ Fork this repository to your GitHub account
2. ğŸŒ¿ Create feature branch: `git checkout -b feature/your-feature-name`
3. ğŸ’» Develop and add corresponding tests
4. ğŸ“ Commit changes: `git commit -m "feat: add your feature"`
5. ğŸ“¤ Push to your repository: `git push origin feature/your-feature-name`
6. ğŸ”„ Create Pull Request to main repository

#### ğŸ¨ Code Standards
* ğŸ Python code follows [PEP 8](https://pep8.org/) specifications
* ğŸ“– Add appropriate documentation and comments for new features

### ğŸ§© Workflow Contributions
* ğŸ“¦ Share your ComfyUI workflows with the community
* ğŸ› ï¸ Submit tested workflow files
* ğŸ“š Add usage instructions and examples for workflows

### ğŸ’¬ Community Communication
* ğŸ¯ Participate in [Discussions](https://github.com/AIDC-AI/Pixelle-MCP/discussions)
* ğŸ’¡ Share usage experiences and best practices
* ğŸ¤ Help other users solve problems

### ğŸ“‹ Development Environment
Refer to the Quick Start section to set up the development environment. We recommend using source code launch for development debugging.

Thank you for your attention and support for the Pixelle MCP project! ğŸ™

## ğŸ™ Acknowledgments

â¤ï¸ Heartfelt thanks to all the following organizations, projects, and teams for their support in the development and implementation of this project.

* ğŸ§© [ComfyUI](https://github.com/comfyanonymous/ComfyUI)
* ğŸ’¬ [Chainlit](https://github.com/Chainlit/chainlit)
* ğŸ—„ï¸ [Minio](https://github.com/minio/minio)
* ğŸ”Œ [MCP](https://modelcontextprotocol.io/introduction)
* ğŸ¬ [WanVideo](https://github.com/Wan-Video/Wan2.1)
* âš¡ [Flux](https://github.com/black-forest-labs/flux) 

## License
The project is released under the MIT License ([](LICENSE), SPDX-License-identifier: MIT).
